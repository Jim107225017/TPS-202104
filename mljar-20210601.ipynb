{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d3218",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (0.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.2.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: xgboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.5.4)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba3ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# mljar\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect with Google Cloud\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"/content/drive/My Drive/colab/TPS May\"\n",
    "path = r'C:\\Users\\Chen\\Desktop\\Kaggle\\Classifier\\Tabular Playground Series - Apr 2021'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca74ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "Survived           0\n",
       "Pclass             0\n",
       "Name               0\n",
       "Sex                0\n",
       "Age             3292\n",
       "SibSp              0\n",
       "Parch              0\n",
       "Ticket          4623\n",
       "Fare             134\n",
       "Cabin          67866\n",
       "Embarked         250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd51912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "0            0         1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1            1         0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2            2         0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3            3         0       3     Kramer, James  male  19.00      0      0   \n",
       "4            4         1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "      Ticket   Fare   Cabin Embarked  \n",
       "0     209245  27.14  C12239        S  \n",
       "1      27323  13.35     NaN        S  \n",
       "2  CA 457703  71.29     NaN        S  \n",
       "3   A. 10866  13.04     NaN        S  \n",
       "4     427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c7c9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train, df_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa1c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Age is float64!!!\n",
      "count    193221.000000\n",
      "mean         34.464565\n",
      "std          16.783847\n",
      "min           0.080000\n",
      "25%          22.000000\n",
      "50%          31.000000\n",
      "75%          48.000000\n",
      "max          87.000000\n",
      "Name: Age, dtype: float64\n",
      "Missing ratio for train is 0.033\n",
      "Missing ratio for test is 0.035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1.Missing value of Age = mean\n",
    "vari = 'Age'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna(all_data[vari].mean())\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5facd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Ticket is object!!!\n",
      "count     190196\n",
      "unique    132613\n",
      "top         A/5 \n",
      "freq         646\n",
      "Name: Ticket, dtype: object\n",
      "Missing ratio for train is 0.046\n",
      "Missing ratio for test is 0.052\n",
      "There is 50 unique values in array : ['X' 'CA' 'A.' 'A/S' 'PC' 'W./C.' 'SC/PARIS' 'S.C./PARIS' 'SC/Paris' 'CA.'\n",
      " 'SOTON/O.Q.' 'C.A.' 'A/5.' 'STON/O' 'A/4' 'C' 'AQ/4' 'STON/O2.' 'WE/P'\n",
      " 'F.C.' 'F.C.C.' 'PP' 'S.O.C.' 'SC/AH' 'Fa' 'W.E.P.' 'C.A./SOTON' 'P/PP'\n",
      " 'A/5' 'SOTON/O2' 'SW/PP' 'STON/OQ.' 'W/C' 'S.O./P.P.' 'SC' 'A./5.' 'A/4.'\n",
      " 'S.O.P.' 'SOTON/OQ' 'SO/C' 'SCO/W' 'A.5.' 'S.W./PP' 'S.P.' 'LP' 'SC/A4'\n",
      " 'AQ/3.' 'S.C./A.4.' 'A4.' 'SC/A.3'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2.Missing value of Ticket = 'X', split string and take first part\n",
    "vari = 'Ticket'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34933f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Fare is float64!!!\n",
      "count    199733.000000\n",
      "mean         44.652071\n",
      "std          67.436104\n",
      "min           0.050000\n",
      "25%          10.080000\n",
      "50%          20.250000\n",
      "75%          34.850000\n",
      "max         744.660000\n",
      "Name: Fare, dtype: float64\n",
      "Missing ratio for train is 0.001\n",
      "Missing ratio for test is 0.001\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3.Missing value of Fare = median by each Pclass and use log transform\n",
    "vari = 'Fare'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "fare_map = all_data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "all_data['Fare'] = all_data['Fare'].fillna(all_data['Pclass'].map(fare_map['Fare']))\n",
    "all_data['Fare'] = np.log1p(all_data['Fare'])   # log1p = log(x+1) : Gaussian transform\n",
    "\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94889712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Cabin is object!!!\n",
      "count      61303\n",
      "unique     45442\n",
      "top       C10839\n",
      "freq           7\n",
      "Name: Cabin, dtype: object\n",
      "Missing ratio for train is 0.679\n",
      "Missing ratio for test is 0.708\n",
      "There is 9 unique values in array : ['C' 'X' 'A' 'D' 'B' 'E' 'F' 'G' 'T'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 4.Missing value of Cabin = 'X' and take first letter\n",
    "vari = 'Cabin'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x: x[0].strip())\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())\n",
    "\n",
    "# or drop the feature directly\n",
    "# for d in [df_train, df_test]:\n",
    "#     d.drop(vari, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "338f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Embarked is object!!!\n",
      "count     199473\n",
      "unique         3\n",
      "top            S\n",
      "freq      140981\n",
      "Name: Embarked, dtype: object\n",
      "Missing ratio for train is 0.003\n",
      "Missing ratio for test is 0.003\n",
      "There is 4 unique values in array : ['S' 'C' 'Q' 'X'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 5.Missing value of Embarked = 'X'\n",
    "vari = 'Embarked'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32856092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 26470 unique values in array : ['Oconnor' 'Bryan' 'Owens' ... 'Pecatoste' 'Conlisk' 'Peitz'] \n"
     ]
    }
   ],
   "source": [
    "# 6.Name, take only surnames\n",
    "vari = 'Name'\n",
    "all_data[vari] = all_data[vari].map(lambda x: x.split(',')[0])\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915e2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and transform\n",
    "label_cols = ['Name', 'Ticket', 'Sex']\n",
    "onehot_cols = ['Cabin', 'Embarked']\n",
    "num_cols = ['Pclass', 'Age', 'SibSp', 'Parch']\n",
    "TARGET = 'Survived'\n",
    "\n",
    "def label_encoder(c):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(c)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot_encoded_df = pd.get_dummies(all_data[onehot_cols])\n",
    "label_encoded_df = all_data[label_cols].apply(label_encoder)\n",
    "num_df = pd.DataFrame(scaler.fit_transform(all_data[num_cols]), columns=num_cols)\n",
    "fare_df = all_data['Fare']\n",
    "target_df = all_data[TARGET]\n",
    "\n",
    "all_data = pd.concat([num_df, fare_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b3dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "df_train = all_data[:len(df_train)]\n",
    "df_test = all_data[len(df_train):].drop(TARGET, axis=1)\n",
    "\n",
    "y = df_train[TARGET]\n",
    "y = pd.DataFrame(y).astype('int64')\n",
    "\n",
    "col = [i for i in df_train.columns if i not in ['PassengerId', 'Survived']]\n",
    "x = df_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4363e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass           Age     SibSp     Parch      Fare   Name  Ticket  Sex  \\\n",
      "0 -1.425730 -8.614253e-16  1.901268 -0.505478  3.337192  17441      49    1   \n",
      "1  0.877699 -8.614253e-16 -0.539572 -0.505478  2.663750   3063      49    1   \n",
      "2  0.877699 -2.069149e+00  0.680848  1.628715  4.280686  17798      14    1   \n",
      "3  0.877699 -9.374220e-01 -0.539572 -0.505478  2.641910  12742       0    1   \n",
      "4  0.877699 -5.737175e-01 -0.539572 -0.505478  2.170196   2335      49    1   \n",
      "\n",
      "   Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \\\n",
      "0        0        0  ...        0        0        0        0        0   \n",
      "1        0        0  ...        0        0        0        0        0   \n",
      "2        0        0  ...        0        0        0        0        0   \n",
      "3        0        0  ...        0        0        0        0        0   \n",
      "4        0        0  ...        0        0        0        0        0   \n",
      "\n",
      "   Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
      "0        0           0           0           1           0  \n",
      "1        1           0           0           1           0  \n",
      "2        1           0           0           1           0  \n",
      "3        1           0           0           1           0  \n",
      "4        1           0           0           1           0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(100000, 21)\n"
     ]
    }
   ],
   "source": [
    "print(x.head())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb77e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "# AutoML : mljar\n",
    "RESULTS_PATH = 'mljar-20210601'\n",
    "SEED = 20210601\n",
    "\n",
    "cv = {\"validation_type\": \"kfold\",\n",
    "      \"k_folds\": 5,\n",
    "      \"shuffle\": True,\n",
    "      \"stratify\": True,\n",
    "      \"random_seed\": SEED}\n",
    "\n",
    "automl = AutoML(results_path=RESULTS_PATH,\n",
    "                mode=\"Optuna\",                          # or 'Explain', 'Perform', 'Compete'\n",
    "                ml_task='binary_classification',        # or 'auto', 'binary_classification', 'regression'\n",
    "                algorithms=['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors'],\n",
    "                train_ensemble=True,\n",
    "                stack_models=True,\n",
    "                eval_metric='accuracy',\n",
    "                validation_strategy=cv,\n",
    "                golden_features=True,\n",
    "                boost_on_errors=True,\n",
    "                optuna_time_budget=60*60,\n",
    "                total_time_limit=8*60*60,\n",
    "                optuna_verbose=False,\n",
    "                n_jobs=-1,\n",
    "                random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b27311b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: mljar-20210601\n",
      "Expected computing time:\n",
      "Total training time: Optuna + ML training = 61200 seconds\n",
      "Total Optuna time: len(algorithms) * optuna_time_budget = 32400 seconds\n",
      "Total ML model training time: 28800 seconds\n",
      "The task is binary_classification with evaluation metric accuracy\n",
      "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'golden_features', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_Baseline accuracy 0.57226 trained in 21.2 seconds\n",
      "2_DecisionTree accuracy 0.75798 trained in 20.76 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "3_Optuna_LightGBM accuracy 0.78386 trained in 39.31 seconds\n",
      "4_Optuna_Xgboost accuracy 0.78219 trained in 43.67 seconds\n",
      "5_Optuna_CatBoost accuracy 0.78361 trained in 38.55 seconds\n",
      "6_Optuna_NeuralNetwork accuracy 0.78041 trained in 461.75 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Sex_ratio_Pclass\n",
      "Add Golden Feature: Pclass_ratio_Sex\n",
      "Add Golden Feature: Sex_multiply_Pclass\n",
      "Add Golden Feature: Sex_diff_Embarked_C\n",
      "Add Golden Feature: Embarked_S_sum_Sex\n",
      "Add Golden Feature: Fare_ratio_Sex\n",
      "Add Golden Feature: Sex_multiply_Fare\n",
      "Add Golden Feature: Sex_diff_Cabin_C\n",
      "Add Golden Feature: Cabin_X_sum_Sex\n",
      "Add Golden Feature: Embarked_S_ratio_Sex\n",
      "Created 10 Golden Features in 11.51 seconds.\n",
      "3_Optuna_LightGBM_GoldenFeatures accuracy 0.78386 trained in 53.29 seconds\n",
      "5_Optuna_CatBoost_GoldenFeatures accuracy 0.78338 trained in 42.39 seconds\n",
      "4_Optuna_Xgboost_GoldenFeatures accuracy 0.78152 trained in 50.5 seconds\n",
      "* Step boost_on_errors will try to check up to 1 model\n",
      "3_Optuna_LightGBM_BoostOnErrors accuracy 0.78308 trained in 44.18 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble accuracy 0.78386 trained in 18.62 seconds\n",
      "* Step stack will try to check up to 7 models\n",
      "3_Optuna_LightGBM_Stacked accuracy 0.78357 trained in 29.96 seconds\n",
      "5_Optuna_CatBoost_Stacked accuracy 0.7835 trained in 26.49 seconds\n",
      "4_Optuna_Xgboost_Stacked accuracy 0.78393 trained in 57.11 seconds\n",
      "6_Optuna_NeuralNetwork_Stacked accuracy 0.78224 trained in 629.09 seconds\n",
      "3_Optuna_LightGBM_GoldenFeatures_Stacked accuracy 0.7834 trained in 34.39 seconds\n",
      "5_Optuna_CatBoost_GoldenFeatures_Stacked accuracy 0.78376 trained in 35.29 seconds\n",
      "4_Optuna_Xgboost_GoldenFeatures_Stacked accuracy 0.78385 trained in 43.71 seconds\n",
      "* Step ensemble_stacked will try to check up to 1 model\n",
      "Ensemble_Stacked accuracy 0.78432 trained in 20.98 seconds\n",
      "AutoML fit time: 16730.19 seconds\n",
      "AutoML best model: Ensemble_Stacked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(algorithms=['Baseline', 'Linear', 'Decision Tree', 'Random Forest',\n",
       "                   'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost',\n",
       "                   'Neural Network', 'Nearest Neighbors'],\n",
       "       boost_on_errors=True, eval_metric='accuracy', golden_features=True,\n",
       "       ml_task='binary_classification', mode='Optuna', optuna_time_budget=3600,\n",
       "       optuna_verbose=False, random_state=20210601,\n",
       "       results_path='mljar-20210601', stack_models=True, total_time_limit=28800,\n",
       "       validation_strategy={'k_folds': 5, 'random_seed': 20210601,\n",
       "                            'shuffle': True, 'stratify': True,\n",
       "                            'validation_type': 'kfold'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "automl.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b872cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load well-trained model\n",
    "automl = AutoML(results_path=RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8f0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "x_test = df_test\n",
    "result = automl.predict(x_test)\n",
    "result = result.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bcb3b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub[sub.columns[1:]] = result\n",
    "sub.to_csv(f'{RESULTS_PATH}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eff0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
