{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d3218",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (0.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.2.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: xgboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.5.4)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install mljar-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ba3ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# mljar\n",
    "from supervised.automl import AutoML\n",
    "\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect with Google Cloud\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"/content/drive/My Drive/colab/TPS May\"\n",
    "path = r'C:\\Users\\Chen\\Desktop\\Kaggle\\Classifier\\Tabular Playground Series - Apr 2021'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca74ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "Survived           0\n",
       "Pclass             0\n",
       "Name               0\n",
       "Sex                0\n",
       "Age             3292\n",
       "SibSp              0\n",
       "Parch              0\n",
       "Ticket          4623\n",
       "Fare             134\n",
       "Cabin          67866\n",
       "Embarked         250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd51912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "0            0         1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1            1         0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2            2         0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3            3         0       3     Kramer, James  male  19.00      0      0   \n",
       "4            4         1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "      Ticket   Fare   Cabin Embarked  \n",
       "0     209245  27.14  C12239        S  \n",
       "1      27323  13.35     NaN        S  \n",
       "2  CA 457703  71.29     NaN        S  \n",
       "3   A. 10866  13.04     NaN        S  \n",
       "4     427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e97da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train, df_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa1c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Age is float64!!!\n",
      "count    193221.000000\n",
      "mean         34.464565\n",
      "std          16.783847\n",
      "min           0.080000\n",
      "25%          22.000000\n",
      "50%          31.000000\n",
      "75%          48.000000\n",
      "max          87.000000\n",
      "Name: Age, dtype: float64\n",
      "Missing ratio for train is 0.033\n",
      "Missing ratio for test is 0.035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1.Missing value of Age = mean\n",
    "vari = 'Age'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna(all_data[vari].mean())\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b5facd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Ticket is object!!!\n",
      "count     200000\n",
      "unique        50\n",
      "top            X\n",
      "freq      152454\n",
      "Name: Ticket, dtype: object\n",
      "Missing ratio for train is 0.046\n",
      "Missing ratio for test is 0.052\n",
      "There is 1 unique values in array : ['X'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2.Missing value of Ticket = 'X', split string and take first part\n",
    "vari = 'Ticket'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34933f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Fare is float64!!!\n",
      "count    199733.000000\n",
      "mean         44.652071\n",
      "std          67.436104\n",
      "min           0.050000\n",
      "25%          10.080000\n",
      "50%          20.250000\n",
      "75%          34.850000\n",
      "max         744.660000\n",
      "Name: Fare, dtype: float64\n",
      "Missing ratio for train is 0.001\n",
      "Missing ratio for test is 0.001\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3.Missing value of Fare = median by each Pclass and use log transform\n",
    "vari = 'Fare'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "fare_map = all_data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "all_data['Fare'] = all_data['Fare'].fillna(all_data['Pclass'].map(fare_map['Fare']))\n",
    "all_data['Fare'] = np.log1p(all_data['Fare'])   # log1p = log(x+1) : Gaussian transform\n",
    "\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94889712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Cabin is object!!!\n",
      "count      61303\n",
      "unique     45442\n",
      "top       C10839\n",
      "freq           7\n",
      "Name: Cabin, dtype: object\n",
      "Missing ratio for train is 0.679\n",
      "Missing ratio for test is 0.708\n",
      "There is 9 unique values in array : ['C' 'X' 'A' 'D' 'B' 'E' 'F' 'G' 'T'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 4.Missing value of Cabin = 'X' and take first letter\n",
    "vari = 'Cabin'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x: x[0].strip())\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())\n",
    "\n",
    "# or drop the feature directly\n",
    "# for d in [df_train, df_test]:\n",
    "#     d.drop(vari, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "338f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Embarked is object!!!\n",
      "count     199473\n",
      "unique         3\n",
      "top            S\n",
      "freq      140981\n",
      "Name: Embarked, dtype: object\n",
      "Missing ratio for train is 0.003\n",
      "Missing ratio for test is 0.003\n",
      "There is 4 unique values in array : ['S' 'C' 'Q' 'X'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 5.Missing value of Embarked = 'X'\n",
    "vari = 'Embarked'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72d48a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 26470 unique values in array : ['Oconnor' 'Bryan' 'Owens' ... 'Pecatoste' 'Conlisk' 'Peitz'] \n"
     ]
    }
   ],
   "source": [
    "# 6.Name, take only surnames\n",
    "vari = 'Name'\n",
    "all_data[vari] = all_data[vari].map(lambda x: x.split(',')[0])\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "915e2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and transform\n",
    "label_cols = ['Name', 'Ticket', 'Sex']\n",
    "onehot_cols = ['Cabin', 'Embarked']\n",
    "num_cols = ['Pclass', 'Age', 'SibSp', 'Parch']\n",
    "TARGET = 'Survived'\n",
    "\n",
    "def label_encoder(c):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(c)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot_encoded_df = pd.get_dummies(all_data[onehot_cols])\n",
    "label_encoded_df = all_data[label_cols].apply(label_encoder)\n",
    "num_df = pd.DataFrame(scaler.fit_transform(all_data[num_cols]), columns=num_cols)\n",
    "fare_df = all_data['Fare']\n",
    "target_df = all_data[TARGET]\n",
    "\n",
    "all_data = pd.concat([num_df, fare_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09b03211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_X</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>0.877699</td>\n",
       "      <td>-0.937422</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>4.159039</td>\n",
       "      <td>10830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>0.877699</td>\n",
       "      <td>1.123570</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>1.918392</td>\n",
       "      <td>17134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>-1.425730</td>\n",
       "      <td>-0.937422</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>3.686627</td>\n",
       "      <td>9978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>-0.274016</td>\n",
       "      <td>-0.573717</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>2.634045</td>\n",
       "      <td>13303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>-1.425730</td>\n",
       "      <td>-1.058657</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>1.628715</td>\n",
       "      <td>3.328268</td>\n",
       "      <td>4406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0.877699</td>\n",
       "      <td>-0.452483</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>2.408745</td>\n",
       "      <td>3844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>-1.425730</td>\n",
       "      <td>1.487275</td>\n",
       "      <td>0.680848</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>4.238589</td>\n",
       "      <td>2992</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.877699</td>\n",
       "      <td>0.759866</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>-0.505478</td>\n",
       "      <td>2.474014</td>\n",
       "      <td>13842</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>-1.425730</td>\n",
       "      <td>0.881101</td>\n",
       "      <td>0.680848</td>\n",
       "      <td>1.628715</td>\n",
       "      <td>3.423611</td>\n",
       "      <td>11475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>-1.425730</td>\n",
       "      <td>0.396161</td>\n",
       "      <td>-0.539572</td>\n",
       "      <td>1.628715</td>\n",
       "      <td>5.280204</td>\n",
       "      <td>7730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pclass       Age     SibSp     Parch      Fare   Name  Ticket  Sex  \\\n",
       "100000  0.877699 -0.937422 -0.539572 -0.505478  4.159039  10830       0    1   \n",
       "100001  0.877699  1.123570 -0.539572 -0.505478  1.918392  17134       0    0   \n",
       "100002 -1.425730 -0.937422 -0.539572 -0.505478  3.686627   9978       0    0   \n",
       "100003 -0.274016 -0.573717 -0.539572 -0.505478  2.634045  13303       0    1   \n",
       "100004 -1.425730 -1.058657 -0.539572  1.628715  3.328268   4406       0    0   \n",
       "...          ...       ...       ...       ...       ...    ...     ...  ...   \n",
       "199995  0.877699 -0.452483 -0.539572 -0.505478  2.408745   3844       0    0   \n",
       "199996 -1.425730  1.487275  0.680848 -0.505478  4.238589   2992       0    1   \n",
       "199997  0.877699  0.759866 -0.539572 -0.505478  2.474014  13842       0    1   \n",
       "199998 -1.425730  0.881101  0.680848  1.628715  3.423611  11475       0    0   \n",
       "199999 -1.425730  0.396161 -0.539572  1.628715  5.280204   7730       0    0   \n",
       "\n",
       "        Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_T  \\\n",
       "100000        0        0  ...        0        0        0        0        0   \n",
       "100001        0        0  ...        0        0        0        0        0   \n",
       "100002        0        1  ...        0        0        0        0        0   \n",
       "100003        0        0  ...        0        0        0        0        0   \n",
       "100004        0        1  ...        0        0        0        0        0   \n",
       "...         ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "199995        0        0  ...        0        0        0        0        0   \n",
       "199996        0        0  ...        0        0        0        0        0   \n",
       "199997        0        0  ...        0        0        0        0        0   \n",
       "199998        0        1  ...        0        0        0        0        0   \n",
       "199999        0        0  ...        0        1        0        0        0   \n",
       "\n",
       "        Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       "100000        1           0           0           1           0  \n",
       "100001        1           0           0           1           0  \n",
       "100002        0           1           0           0           0  \n",
       "100003        1           0           0           1           0  \n",
       "100004        0           1           0           0           0  \n",
       "...         ...         ...         ...         ...         ...  \n",
       "199995        1           0           1           0           0  \n",
       "199996        1           0           0           1           0  \n",
       "199997        1           0           0           1           0  \n",
       "199998        0           1           0           0           0  \n",
       "199999        0           1           0           0           0  \n",
       "\n",
       "[100000 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train and test\n",
    "# df_train = all_data[:len(df_train)]\n",
    "all_data[len(df_train):].drop(TARGET, axis=1)\n",
    "\n",
    "# y = df_train['Survived']\n",
    "# y = pd.DataFrame(y).astype('int64')\n",
    "\n",
    "# col = [i for i in df_train.columns if i not in ['PassengerId', 'Survived']]\n",
    "# x = df_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb77e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "# AutoML : mljar\n",
    "RESULTS_PATH = 'mljar-20210531'\n",
    "SEED = 20210531\n",
    "\n",
    "cv = {\"validation_type\": \"kfold\",\n",
    "      \"k_folds\": 5,\n",
    "      \"shuffle\": True,\n",
    "      \"stratify\": True,\n",
    "      \"random_seed\": SEED}\n",
    "\n",
    "automl = AutoML(results_path=RESULTS_PATH,\n",
    "                mode=\"Optuna\",                          # or 'Explain', 'Perform', 'Compete'\n",
    "                ml_task='binary_classification',        # or 'auto', 'binary_classification', 'regression'\n",
    "                algorithms=['Baseline', 'Linear', 'Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors'],\n",
    "                train_ensemble=True,\n",
    "                stack_models=True,\n",
    "                eval_metric='accuracy',\n",
    "                validation_strategy=cv,\n",
    "                golden_features=True,\n",
    "                boost_on_errors=True,\n",
    "                optuna_time_budget=60*60,\n",
    "                total_time_limit=8*60*60,\n",
    "                optuna_verbose=False,\n",
    "                n_jobs=-1,\n",
    "                random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b27311b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: mljar-20210531\n",
      "Expected computing time:\n",
      "Total training time: Optuna + ML training = 61200 seconds\n",
      "Total Optuna time: len(algorithms) * optuna_time_budget = 32400 seconds\n",
      "Total ML model training time: 28800 seconds\n",
      "The task is binary_classification with evaluation metric accuracy\n",
      "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'golden_features', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_Baseline: trained.\n",
      "2_DecisionTree: trained.\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "3_Optuna_LightGBM accuracy 0.77676 trained in 127.05 seconds\n",
      "4_Optuna_Xgboost accuracy 0.77689 trained in 202.33 seconds\n",
      "There was an error during 5_Optuna_CatBoost training.\n",
      "Please check mljar-20210531\\errors.md for details.\n",
      "6_Optuna_NeuralNetwork accuracy 0.76754 trained in 393.39 seconds\n",
      "7_Optuna_RandomForest accuracy 0.77543 trained in 216.66 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Pclass_diff_Parch\n",
      "Add Golden Feature: Pclass_diff_SibSp\n",
      "Add Golden Feature: Pclass_ratio_Age\n",
      "Add Golden Feature: Age_ratio_Pclass\n",
      "Add Golden Feature: Parch_sum_Pclass\n",
      "Add Golden Feature: SibSp_sum_Pclass\n",
      "Add Golden Feature: Fare_multiply_Age\n",
      "Add Golden Feature: Fare_sum_Age\n",
      "Add Golden Feature: Fare_multiply_Pclass\n",
      "Add Golden Feature: Fare_ratio_Pclass\n",
      "Created 10 Golden Features in 10.98 seconds.\n",
      "4_Optuna_Xgboost_GoldenFeatures accuracy 0.77466 trained in 226.67 seconds\n",
      "3_Optuna_LightGBM_GoldenFeatures accuracy 0.77566 trained in 110.67 seconds\n",
      "7_Optuna_RandomForest_GoldenFeatures accuracy 0.77537 trained in 217.6 seconds\n",
      "* Step boost_on_errors will try to check up to 1 model\n",
      "4_Optuna_Xgboost_BoostOnErrors accuracy 0.77663 trained in 191.93 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble accuracy 0.77761 trained in 18.61 seconds\n",
      "* Step stack will try to check up to 7 models\n",
      "4_Optuna_Xgboost_Stacked accuracy 0.77735 trained in 138.05 seconds\n",
      "3_Optuna_LightGBM_Stacked accuracy 0.77727 trained in 109.13 seconds\n",
      "7_Optuna_RandomForest_Stacked accuracy 0.778 trained in 184.8 seconds\n",
      "6_Optuna_NeuralNetwork_Stacked accuracy 0.77438 trained in 327.57 seconds\n",
      "4_Optuna_Xgboost_GoldenFeatures_Stacked accuracy 0.77693 trained in 138.58 seconds\n",
      "3_Optuna_LightGBM_GoldenFeatures_Stacked accuracy 0.77644 trained in 110.0 seconds\n",
      "7_Optuna_RandomForest_GoldenFeatures_Stacked accuracy 0.77808 trained in 212.05 seconds\n",
      "* Step ensemble_stacked will try to check up to 1 model\n",
      "Ensemble_Stacked accuracy 0.77808 trained in 18.68 seconds\n",
      "AutoML fit time: 17859.46 seconds\n",
      "AutoML best model: 7_Optuna_RandomForest_GoldenFeatures_Stacked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(algorithms=['Baseline', 'Linear', 'Decision Tree', 'Random Forest',\n",
       "                   'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost',\n",
       "                   'Neural Network', 'Nearest Neighbors'],\n",
       "       boost_on_errors=True, eval_metric='accuracy', golden_features=True,\n",
       "       ml_task='binary_classification', mode='Optuna', optuna_time_budget=3600,\n",
       "       optuna_verbose=False, random_state=20210531,\n",
       "       results_path='mljar-20210531', stack_models=True, total_time_limit=28800,\n",
       "       validation_strategy={'k_folds': 5, 'random_seed': 20210531,\n",
       "                            'shuffle': True, 'stratify': True,\n",
       "                            'validation_type': 'kfold'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "automl.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b872cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load well-trained model\n",
    "automl = AutoML(results_path=RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c8f0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "x_test = df_test.drop(['PassengerId'], axis=1)\n",
    "result = automl.predict(x_test)\n",
    "result = result.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bcb3b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub[sub.columns[1:]] = result\n",
    "sub.to_csv(f'{RESULTS_PATH}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eff0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
