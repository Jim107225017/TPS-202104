{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU version\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA/cuDNN Version\n",
    "!nvcc -V && which nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d3218",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (0.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.2.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (4.14.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: xgboost in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\chen\\anaconda3\\envs\\ml\\lib\\site-packages (from xgboost) (1.5.4)\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install catboost\n",
    "!pip install xgboost\n",
    "!pip install pycaret[full]\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f15cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 即時監控colab資源\n",
    "import wandb\n",
    "\n",
    "# connect with jim107225017/colab/20210526\n",
    "wandb.init(project='colab', entity='jim107225017', name='CPU_GPU', id='20210526')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99af491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install lightgbm GPU in colab\n",
    "# 先登入google cloud\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip uninstall lightgbm -y\n",
    "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
    "!cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba3ec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chen\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Chen\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Chen\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pycaret\n",
    "from pycaret.classification import *\n",
    "\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98da66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # connect with Google Cloud\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"/content/drive/My Drive/colab/TPS May\"\n",
    "path = r'C:\\Users\\Chen\\Desktop\\Kaggle\\Classifier\\Tabular Playground Series - Apr 2021'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac58004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca74ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "Survived           0\n",
       "Pclass             0\n",
       "Name               0\n",
       "Sex                0\n",
       "Age             3292\n",
       "SibSp              0\n",
       "Parch              0\n",
       "Ticket          4623\n",
       "Fare             134\n",
       "Cabin          67866\n",
       "Embarked         250\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd51912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Oconnor, Frankie</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209245</td>\n",
       "      <td>27.14</td>\n",
       "      <td>C12239</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bryan, Drew</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27323</td>\n",
       "      <td>13.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owens, Kenneth</td>\n",
       "      <td>male</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 457703</td>\n",
       "      <td>71.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kramer, James</td>\n",
       "      <td>male</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A. 10866</td>\n",
       "      <td>13.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bond, Michael</td>\n",
       "      <td>male</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427635</td>\n",
       "      <td>7.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\n",
       "0            0         1       1  Oconnor, Frankie  male    NaN      2      0   \n",
       "1            1         0       3       Bryan, Drew  male    NaN      0      0   \n",
       "2            2         0       3    Owens, Kenneth  male   0.33      1      2   \n",
       "3            3         0       3     Kramer, James  male  19.00      0      0   \n",
       "4            4         1       3     Bond, Michael  male  25.00      0      0   \n",
       "\n",
       "      Ticket   Fare   Cabin Embarked  \n",
       "0     209245  27.14  C12239        S  \n",
       "1      27323  13.35     NaN        S  \n",
       "2  CA 457703  71.29     NaN        S  \n",
       "3   A. 10866  13.04     NaN        S  \n",
       "4     427635   7.76     NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7c9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([df_train, df_test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa1c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Age is float64!!!\n",
      "count    193221.000000\n",
      "mean         34.464565\n",
      "std          16.783847\n",
      "min           0.080000\n",
      "25%          22.000000\n",
      "50%          31.000000\n",
      "75%          48.000000\n",
      "max          87.000000\n",
      "Name: Age, dtype: float64\n",
      "Missing ratio for train is 0.033\n",
      "Missing ratio for test is 0.035\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1.Missing value of Age = mean\n",
    "vari = 'Age'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna(all_data[vari].mean())\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b5facd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Ticket is object!!!\n",
      "count     190196\n",
      "unique    132613\n",
      "top         A/5 \n",
      "freq         646\n",
      "Name: Ticket, dtype: object\n",
      "Missing ratio for train is 0.046\n",
      "Missing ratio for test is 0.052\n",
      "There is 50 unique values in array : ['X' 'CA' 'A.' 'A/S' 'PC' 'W./C.' 'SC/PARIS' 'S.C./PARIS' 'SC/Paris' 'CA.'\n",
      " 'SOTON/O.Q.' 'C.A.' 'A/5.' 'STON/O' 'A/4' 'C' 'AQ/4' 'STON/O2.' 'WE/P'\n",
      " 'F.C.' 'F.C.C.' 'PP' 'S.O.C.' 'SC/AH' 'Fa' 'W.E.P.' 'C.A./SOTON' 'P/PP'\n",
      " 'A/5' 'SOTON/O2' 'SW/PP' 'STON/OQ.' 'W/C' 'S.O./P.P.' 'SC' 'A./5.' 'A/4.'\n",
      " 'S.O.P.' 'SOTON/OQ' 'SO/C' 'SCO/W' 'A.5.' 'S.W./PP' 'S.P.' 'LP' 'SC/A4'\n",
      " 'AQ/3.' 'S.C./A.4.' 'A4.' 'SC/A.3'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2.Missing value of Ticket = 'X', split string and take first part\n",
    "vari = 'Ticket'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34933f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Fare is float64!!!\n",
      "count    199733.000000\n",
      "mean         44.652071\n",
      "std          67.436104\n",
      "min           0.050000\n",
      "25%          10.080000\n",
      "50%          20.250000\n",
      "75%          34.850000\n",
      "max         744.660000\n",
      "Name: Fare, dtype: float64\n",
      "Missing ratio for train is 0.001\n",
      "Missing ratio for test is 0.001\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 3.Missing value of Fare = median by each Pclass and use log transform\n",
    "vari = 'Fare'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "fare_map = all_data[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "all_data['Fare'] = all_data['Fare'].fillna(all_data['Pclass'].map(fare_map['Fare']))\n",
    "all_data['Fare'] = np.log1p(all_data['Fare'])   # log1p = log(x+1) : Gaussian transform\n",
    "\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94889712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Cabin is object!!!\n",
      "count      61303\n",
      "unique     45442\n",
      "top       C10839\n",
      "freq           7\n",
      "Name: Cabin, dtype: object\n",
      "Missing ratio for train is 0.679\n",
      "Missing ratio for test is 0.708\n",
      "There is 9 unique values in array : ['C' 'X' 'A' 'D' 'B' 'E' 'F' 'G' 'T'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 4.Missing value of Cabin = 'X' and take first letter\n",
    "vari = 'Cabin'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X').map(lambda x: x[0].strip())\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())\n",
    "\n",
    "# or drop the feature directly\n",
    "# for d in [df_train, df_test]:\n",
    "#     d.drop(vari, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338f736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Embarked is object!!!\n",
      "count     199473\n",
      "unique         3\n",
      "top            S\n",
      "freq      140981\n",
      "Name: Embarked, dtype: object\n",
      "Missing ratio for train is 0.003\n",
      "Missing ratio for test is 0.003\n",
      "There is 4 unique values in array : ['S' 'C' 'Q' 'X'] \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 5.Missing value of Embarked = 'X'\n",
    "vari = 'Embarked'\n",
    "print(f\"Type {vari} is {all_data[vari].dtype}!!!\")\n",
    "\n",
    "print(all_data[vari].describe())\n",
    "\n",
    "print(f\"Missing ratio for train is {df_train[vari].isnull().sum() / len(df_train):.3f}\")\n",
    "print(f\"Missing ratio for test is {df_test[vari].isnull().sum() / len(df_test):.3f}\")\n",
    "\n",
    "all_data[vari] = all_data[vari].fillna('X')\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')\n",
    "\n",
    "print(all_data[vari].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32856092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 26470 unique values in array : ['Oconnor' 'Bryan' 'Owens' ... 'Pecatoste' 'Conlisk' 'Peitz'] \n"
     ]
    }
   ],
   "source": [
    "# 6.Name, take only surnames\n",
    "vari = 'Name'\n",
    "all_data[vari] = all_data[vari].map(lambda x: x.split(',')[0])\n",
    "\n",
    "print(f'There is {all_data[vari].nunique()} unique values in array : {all_data[vari].unique()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "915e2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and transform\n",
    "label_cols = ['Name', 'Ticket', 'Sex']\n",
    "onehot_cols = ['Cabin', 'Embarked']\n",
    "num_cols = ['Pclass', 'Age', 'Fare', 'SibSp', 'Parch']\n",
    "TARGET = 'Survived'\n",
    "\n",
    "def label_encoder(c):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(c)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "onehot_encoded_df = all_data[onehot_cols]\n",
    "label_encoded_df = all_data[label_cols].apply(label_encoder)\n",
    "num_df = pd.DataFrame(scaler.fit_transform(all_data[num_cols]), columns=num_cols)\n",
    "target_df = all_data[TARGET]\n",
    "\n",
    "all_data = pd.concat([num_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54b3dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "df_train = all_data[:len(df_train)]\n",
    "df_train[TARGET] = df_train[TARGET].astype('int64')\n",
    "\n",
    "df_test = all_data[len(df_train):]\n",
    "df_test[TARGET] = np.int64(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4363e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass           Age      Fare     SibSp     Parch   Name  Ticket  Sex  \\\n",
      "0 -1.425730 -8.614253e-16  0.134351  1.901268 -0.505478  17441      49    1   \n",
      "1  0.877699 -8.614253e-16 -0.533837 -0.539572 -0.505478   3063      49    1   \n",
      "2  0.877699 -2.069149e+00  1.070483  0.680848  1.628715  17798      14    1   \n",
      "3  0.877699 -9.374220e-01 -0.555506 -0.539572 -0.505478  12742       0    1   \n",
      "4  0.877699 -5.737175e-01 -1.023540 -0.539572 -0.505478   2335      49    1   \n",
      "\n",
      "  Cabin Embarked  Survived  \n",
      "0     C        S         1  \n",
      "1     X        S         0  \n",
      "2     X        S         0  \n",
      "3     X        S         0  \n",
      "4     X        S         1  \n",
      "(100000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb77e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_60da7_row18_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_60da7_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Description</th>        <th class=\"col_heading level0 col1\" >Value</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_60da7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_60da7_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "                        <td id=\"T_60da7_row0_col1\" class=\"data row0 col1\" >20210604</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_60da7_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "                        <td id=\"T_60da7_row1_col1\" class=\"data row1 col1\" >Survived</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_60da7_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "                        <td id=\"T_60da7_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_60da7_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "                        <td id=\"T_60da7_row3_col1\" class=\"data row3 col1\" >0: 0, 1: 1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_60da7_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "                        <td id=\"T_60da7_row4_col1\" class=\"data row4 col1\" >(100000, 11)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_60da7_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "                        <td id=\"T_60da7_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_60da7_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "                        <td id=\"T_60da7_row6_col1\" class=\"data row6 col1\" >8</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_60da7_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "                        <td id=\"T_60da7_row7_col1\" class=\"data row7 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_60da7_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "                        <td id=\"T_60da7_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_60da7_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "                        <td id=\"T_60da7_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_60da7_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "                        <td id=\"T_60da7_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_60da7_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "                        <td id=\"T_60da7_row11_col1\" class=\"data row11 col1\" >(100000, 21)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_60da7_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "                        <td id=\"T_60da7_row12_col1\" class=\"data row12 col1\" >(100000, 21)</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_60da7_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "                        <td id=\"T_60da7_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_60da7_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "                        <td id=\"T_60da7_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_60da7_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "                        <td id=\"T_60da7_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_60da7_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "                        <td id=\"T_60da7_row16_col1\" class=\"data row16 col1\" >5</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_60da7_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "                        <td id=\"T_60da7_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_60da7_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "                        <td id=\"T_60da7_row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_60da7_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "                        <td id=\"T_60da7_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_60da7_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "                        <td id=\"T_60da7_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_60da7_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "                        <td id=\"T_60da7_row21_col1\" class=\"data row21 col1\" >998c</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_60da7_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "                        <td id=\"T_60da7_row22_col1\" class=\"data row22 col1\" >iterative</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_60da7_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "                        <td id=\"T_60da7_row23_col1\" class=\"data row23 col1\" >5</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_60da7_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "                        <td id=\"T_60da7_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_60da7_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "                        <td id=\"T_60da7_row25_col1\" class=\"data row25 col1\" >Light Gradient Boosting Machine</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_60da7_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "                        <td id=\"T_60da7_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_60da7_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "                        <td id=\"T_60da7_row27_col1\" class=\"data row27 col1\" >Light Gradient Boosting Machine</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_60da7_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "                        <td id=\"T_60da7_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_60da7_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "                        <td id=\"T_60da7_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_60da7_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "                        <td id=\"T_60da7_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_60da7_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "                        <td id=\"T_60da7_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_60da7_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "                        <td id=\"T_60da7_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_60da7_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "                        <td id=\"T_60da7_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_60da7_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "                        <td id=\"T_60da7_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_60da7_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "                        <td id=\"T_60da7_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_60da7_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "                        <td id=\"T_60da7_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_60da7_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "                        <td id=\"T_60da7_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_60da7_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "                        <td id=\"T_60da7_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_60da7_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "                        <td id=\"T_60da7_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_60da7_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "                        <td id=\"T_60da7_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_60da7_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "                        <td id=\"T_60da7_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_60da7_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "                        <td id=\"T_60da7_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_60da7_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "                        <td id=\"T_60da7_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_60da7_row44_col0\" class=\"data row44 col0\" >Clustering</td>\n",
       "                        <td id=\"T_60da7_row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_60da7_row45_col0\" class=\"data row45 col0\" >Clustering Iteration</td>\n",
       "                        <td id=\"T_60da7_row45_col1\" class=\"data row45 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_60da7_row46_col0\" class=\"data row46 col0\" >Polynomial Features</td>\n",
       "                        <td id=\"T_60da7_row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_60da7_row47_col0\" class=\"data row47 col0\" >Polynomial Degree</td>\n",
       "                        <td id=\"T_60da7_row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_60da7_row48_col0\" class=\"data row48 col0\" >Trignometry Features</td>\n",
       "                        <td id=\"T_60da7_row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_60da7_row49_col0\" class=\"data row49 col0\" >Polynomial Threshold</td>\n",
       "                        <td id=\"T_60da7_row49_col1\" class=\"data row49 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_60da7_row50_col0\" class=\"data row50 col0\" >Group Features</td>\n",
       "                        <td id=\"T_60da7_row50_col1\" class=\"data row50 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_60da7_row51_col0\" class=\"data row51 col0\" >Feature Selection</td>\n",
       "                        <td id=\"T_60da7_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_60da7_row52_col0\" class=\"data row52 col0\" >Feature Selection Method</td>\n",
       "                        <td id=\"T_60da7_row52_col1\" class=\"data row52 col1\" >classic</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_60da7_row53_col0\" class=\"data row53 col0\" >Features Selection Threshold</td>\n",
       "                        <td id=\"T_60da7_row53_col1\" class=\"data row53 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_60da7_row54_col0\" class=\"data row54 col0\" >Feature Interaction</td>\n",
       "                        <td id=\"T_60da7_row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_60da7_row55_col0\" class=\"data row55 col0\" >Feature Ratio</td>\n",
       "                        <td id=\"T_60da7_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_60da7_row56_col0\" class=\"data row56 col0\" >Interaction Threshold</td>\n",
       "                        <td id=\"T_60da7_row56_col1\" class=\"data row56 col1\" >None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_60da7_row57_col0\" class=\"data row57 col0\" >Fix Imbalance</td>\n",
       "                        <td id=\"T_60da7_row57_col1\" class=\"data row57 col1\" >False</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_60da7_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "                        <td id=\"T_60da7_row58_col0\" class=\"data row58 col0\" >Fix Imbalance Method</td>\n",
       "                        <td id=\"T_60da7_row58_col1\" class=\"data row58 col1\" >SMOTE</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1afb0a992c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 'box-cox',\n",
       " {'USI',\n",
       "  'X',\n",
       "  'X_test',\n",
       "  'X_train',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_groups_param_full',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param',\n",
       "  'y',\n",
       "  'y_test',\n",
       "  'y_train'},\n",
       " True,\n",
       " None,\n",
       " [],\n",
       " [('Setup Config',\n",
       "                                  Description                            Value\n",
       "   0                               session_id                         20210604\n",
       "   1                                   Target                         Survived\n",
       "   2                              Target Type                           Binary\n",
       "   3                            Label Encoded                       0: 0, 1: 1\n",
       "   4                            Original Data                     (100000, 11)\n",
       "   5                           Missing Values                            False\n",
       "   6                         Numeric Features                                8\n",
       "   7                     Categorical Features                                2\n",
       "   8                         Ordinal Features                            False\n",
       "   9                High Cardinality Features                            False\n",
       "   10                 High Cardinality Method                             None\n",
       "   11                   Transformed Train Set                     (100000, 21)\n",
       "   12                    Transformed Test Set                     (100000, 21)\n",
       "   13                      Shuffle Train-Test                             True\n",
       "   14                     Stratify Train-Test                             True\n",
       "   15                          Fold Generator                  StratifiedKFold\n",
       "   16                             Fold Number                                5\n",
       "   17                                CPU Jobs                               -1\n",
       "   18                                 Use GPU                             True\n",
       "   19                          Log Experiment                            False\n",
       "   20                         Experiment Name                 clf-default-name\n",
       "   21                                     USI                             998c\n",
       "   22                         Imputation Type                        iterative\n",
       "   23          Iterative Imputation Iteration                                5\n",
       "   24                         Numeric Imputer                             mean\n",
       "   25      Iterative Imputation Numeric Model  Light Gradient Boosting Machine\n",
       "   26                     Categorical Imputer                         constant\n",
       "   27  Iterative Imputation Categorical Model  Light Gradient Boosting Machine\n",
       "   28           Unknown Categoricals Handling                   least_frequent\n",
       "   29                               Normalize                            False\n",
       "   30                        Normalize Method                             None\n",
       "   31                          Transformation                            False\n",
       "   32                   Transformation Method                             None\n",
       "   33                                     PCA                            False\n",
       "   34                              PCA Method                             None\n",
       "   35                          PCA Components                             None\n",
       "   36                     Ignore Low Variance                            False\n",
       "   37                     Combine Rare Levels                            False\n",
       "   38                    Rare Level Threshold                             None\n",
       "   39                         Numeric Binning                            False\n",
       "   40                         Remove Outliers                            False\n",
       "   41                      Outliers Threshold                             None\n",
       "   42                Remove Multicollinearity                            False\n",
       "   43             Multicollinearity Threshold                             None\n",
       "   44                              Clustering                            False\n",
       "   45                    Clustering Iteration                             None\n",
       "   46                     Polynomial Features                            False\n",
       "   47                       Polynomial Degree                             None\n",
       "   48                    Trignometry Features                            False\n",
       "   49                    Polynomial Threshold                             None\n",
       "   50                          Group Features                            False\n",
       "   51                       Feature Selection                            False\n",
       "   52                Feature Selection Method                          classic\n",
       "   53            Features Selection Threshold                             None\n",
       "   54                     Feature Interaction                            False\n",
       "   55                           Feature Ratio                            False\n",
       "   56                   Interaction Threshold                             None\n",
       "   57                           Fix Imbalance                            False\n",
       "   58                    Fix Imbalance Method                            SMOTE),\n",
       "  ('X_training Set',\n",
       "             Name  Ticket  Sex    Pclass           Age      Fare     SibSp  \\\n",
       "   0      17441.0    49.0  1.0 -1.425730 -8.614253e-16  0.134351  1.901268   \n",
       "   1       3063.0    49.0  1.0  0.877699 -8.614253e-16 -0.533837 -0.539572   \n",
       "   2      17798.0    14.0  1.0  0.877699 -2.069149e+00  1.070483  0.680848   \n",
       "   3      12742.0     0.0  1.0  0.877699 -9.374220e-01 -0.555506 -0.539572   \n",
       "   4       2335.0    49.0  1.0  0.877699 -5.737175e-01 -1.023540 -0.539572   \n",
       "   ...        ...     ...  ...       ...           ...       ...       ...   \n",
       "   99995   1590.0    21.0  0.0 -0.274016  1.669127e+00 -0.434567 -0.539572   \n",
       "   99996   2992.0    49.0  1.0 -0.274016  1.911597e+00 -0.698959 -0.539572   \n",
       "   99997   4219.0    49.0  1.0  0.877699  1.536915e-01 -0.802137 -0.539572   \n",
       "   99998   3941.0    49.0  1.0  0.877699  1.002335e+00  0.259408 -0.539572   \n",
       "   99999   7055.0    49.0  1.0  0.877699  1.244805e+00 -0.492531 -0.539572   \n",
       "   \n",
       "             Parch  Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       "   0     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   1     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   2      1.628715      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   3     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   4     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   ...         ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "   99995 -0.505478      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "   99996 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   99997 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   99998  0.561618      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   99999 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   \n",
       "          Cabin_T  Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       "   0          0.0      0.0         0.0         0.0         1.0         0.0  \n",
       "   1          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   2          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   3          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   4          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   ...        ...      ...         ...         ...         ...         ...  \n",
       "   99995      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       "   99996      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   99997      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   99998      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   99999      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   \n",
       "   [100000 rows x 21 columns]),\n",
       "  ('y_training Set',\n",
       "   0        1\n",
       "   1        0\n",
       "   2        0\n",
       "   3        0\n",
       "   4        1\n",
       "           ..\n",
       "   99995    1\n",
       "   99996    0\n",
       "   99997    0\n",
       "   99998    0\n",
       "   99999    0\n",
       "   Name: Survived, Length: 100000, dtype: int32),\n",
       "  ('X_test Set',\n",
       "              Name  Ticket  Sex    Pclass       Age      Fare     SibSp  \\\n",
       "   100000  10830.0    49.0  1.0  0.877699 -0.937422  0.949786 -0.539572   \n",
       "   100001  17134.0    49.0  0.0  0.877699  1.123570 -1.273379 -0.539572   \n",
       "   100002   9978.0    49.0  0.0 -1.425730 -0.937422  0.481059 -0.539572   \n",
       "   100003  13303.0    49.0  1.0 -0.274016 -0.573717 -0.563310 -0.539572   \n",
       "   100004   4406.0    49.0  0.0 -1.425730 -1.058657  0.125497 -0.539572   \n",
       "   ...         ...     ...  ...       ...       ...       ...       ...   \n",
       "   199995   3844.0    49.0  0.0  0.877699 -0.452483 -0.786852 -0.539572   \n",
       "   199996   2992.0    49.0  1.0 -1.425730  1.487275  1.028715  0.680848   \n",
       "   199997  13842.0    49.0  1.0  0.877699  0.759866 -0.722092 -0.539572   \n",
       "   199998  11475.0    21.0  0.0 -1.425730  0.881101  0.220096  0.680848   \n",
       "   199999   7730.0    21.0  0.0 -1.425730  0.396161  2.062203 -0.539572   \n",
       "   \n",
       "              Parch  Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       "   100000 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   100001 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   100002 -0.505478      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       "   100003 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   100004  1.628715      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       "   ...          ...      ...      ...  ...      ...      ...      ...      ...   \n",
       "   199995 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   199996 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   199997 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "   199998  1.628715      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       "   199999  1.628715      0.0      0.0  ...      0.0      1.0      0.0      0.0   \n",
       "   \n",
       "           Cabin_T  Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       "   100000      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   100001      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   100002      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       "   100003      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   100004      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       "   ...         ...      ...         ...         ...         ...         ...  \n",
       "   199995      0.0      1.0         0.0         1.0         0.0         0.0  \n",
       "   199996      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   199997      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       "   199998      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       "   199999      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       "   \n",
       "   [100000 rows x 21 columns]),\n",
       "  ('y_test Set',\n",
       "   100000    1\n",
       "   100001    1\n",
       "   100002    1\n",
       "   100003    1\n",
       "   100004    1\n",
       "            ..\n",
       "   199995    1\n",
       "   199996    1\n",
       "   199997    1\n",
       "   199998    1\n",
       "   199999    1\n",
       "   Name: Survived, Length: 100000, dtype: int64),\n",
       "  ('Transformation Pipeline',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=['Cabin',\n",
       "                                                               'Embarked'],\n",
       "                                         display_types=False, features_todrop=[],\n",
       "                                         id_columns=[],\n",
       "                                         ml_usecase='classification',\n",
       "                                         numerical_features=['Name', 'Ticket',\n",
       "                                                             'Sex', 'Pclass',\n",
       "                                                             'Age', 'Fare',\n",
       "                                                             'SibSp', 'Parch'],\n",
       "                                         target='Survived', time_features=[])),\n",
       "                   ('imputer',\n",
       "                    Iterative_Imputer(add_indicator=False,\n",
       "                                      c...\n",
       "                   ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                   ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                   ('cluster_all', 'passthrough'),\n",
       "                   ('dummy', Dummify(target='Survived')),\n",
       "                   ('fix_perfect', Remove_100(target='Survived')),\n",
       "                   ('clean_names', Clean_Colum_Names()),\n",
       "                   ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "            verbose=False))],\n",
       " [<pandas.io.formats.style.Styler at 0x1afb0a992c8>],\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x1afb53f0dc8>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x1afb53f0d08>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x1afb53b8a48>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x1afb53ebe08>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x1afb53eb6c8>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x1afb53eb188>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x1afb53eb1c8>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x1afb52710c8>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x1afb5271508>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x1afb53eb5c8>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x1afb53bcb08>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x1afb53f0fc8>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x1afb53bc148>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x1afb52717c8>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x1afb5276608>,\n",
       "  'xgboost': <pycaret.containers.models.classification.XGBClassifierContainer at 0x1afb53ba8c8>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x1afb5276048>,\n",
       "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x1afb5276c48>},\n",
       " True,\n",
       " None,\n",
       " 5,\n",
       " None,\n",
       " <MLUsecase.CLASSIFICATION: 1>,\n",
       " True,\n",
       " {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x1afb53f0b08>,\n",
       "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x1afb53f0448>,\n",
       "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x1afb530aa88>,\n",
       "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x1afb530ac08>,\n",
       "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x1afb530ad08>,\n",
       "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x1afb530ae88>,\n",
       "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x1afb530aec8>},\n",
       " -1,\n",
       "            Name  Ticket  Sex    Pclass       Age      Fare     SibSp  \\\n",
       " 100000  10830.0    49.0  1.0  0.877699 -0.937422  0.949786 -0.539572   \n",
       " 100001  17134.0    49.0  0.0  0.877699  1.123570 -1.273379 -0.539572   \n",
       " 100002   9978.0    49.0  0.0 -1.425730 -0.937422  0.481059 -0.539572   \n",
       " 100003  13303.0    49.0  1.0 -0.274016 -0.573717 -0.563310 -0.539572   \n",
       " 100004   4406.0    49.0  0.0 -1.425730 -1.058657  0.125497 -0.539572   \n",
       " ...         ...     ...  ...       ...       ...       ...       ...   \n",
       " 199995   3844.0    49.0  0.0  0.877699 -0.452483 -0.786852 -0.539572   \n",
       " 199996   2992.0    49.0  1.0 -1.425730  1.487275  1.028715  0.680848   \n",
       " 199997  13842.0    49.0  1.0  0.877699  0.759866 -0.722092 -0.539572   \n",
       " 199998  11475.0    21.0  0.0 -1.425730  0.881101  0.220096  0.680848   \n",
       " 199999   7730.0    21.0  0.0 -1.425730  0.396161  2.062203 -0.539572   \n",
       " \n",
       "            Parch  Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       " 100000 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 100001 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 100002 -0.505478      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       " 100003 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 100004  1.628715      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       " ...          ...      ...      ...  ...      ...      ...      ...      ...   \n",
       " 199995 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 199996 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 199997 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 199998  1.628715      0.0      1.0  ...      0.0      0.0      0.0      0.0   \n",
       " 199999  1.628715      0.0      0.0  ...      0.0      1.0      0.0      0.0   \n",
       " \n",
       "         Cabin_T  Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       " 100000      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 100001      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 100002      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " 100003      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 100004      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " ...         ...      ...         ...         ...         ...         ...  \n",
       " 199995      0.0      1.0         0.0         1.0         0.0         0.0  \n",
       " 199996      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 199997      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 199998      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " 199999      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " \n",
       " [100000 rows x 21 columns],\n",
       " False,\n",
       " [],\n",
       " 5,\n",
       "         Name  Ticket  Sex Cabin Embarked    Pclass           Age      Fare  \\\n",
       " 0      17441      49    1     C        S -1.425730 -8.614253e-16  0.134351   \n",
       " 1       3063      49    1     X        S  0.877699 -8.614253e-16 -0.533837   \n",
       " 2      17798      14    1     X        S  0.877699 -2.069149e+00  1.070483   \n",
       " 3      12742       0    1     X        S  0.877699 -9.374220e-01 -0.555506   \n",
       " 4       2335      49    1     X        S  0.877699 -5.737175e-01 -1.023540   \n",
       " ...      ...     ...  ...   ...      ...       ...           ...       ...   \n",
       " 99995   1590      21    0     D        C -0.274016  1.669127e+00 -0.434567   \n",
       " 99996   2992      49    1     X        S -0.274016  1.911597e+00 -0.698959   \n",
       " 99997   4219      49    1     X        S  0.877699  1.536915e-01 -0.802137   \n",
       " 99998   3941      49    1     X        S  0.877699  1.002335e+00  0.259408   \n",
       " 99999   7055      49    1     X        S  0.877699  1.244805e+00 -0.492531   \n",
       " \n",
       "           SibSp     Parch  Survived  \n",
       " 0      1.901268 -0.505478         1  \n",
       " 1     -0.539572 -0.505478         0  \n",
       " 2      0.680848  1.628715         0  \n",
       " 3     -0.539572 -0.505478         0  \n",
       " 4     -0.539572 -0.505478         1  \n",
       " ...         ...       ...       ...  \n",
       " 99995 -0.539572 -0.505478         1  \n",
       " 99996 -0.539572 -0.505478         0  \n",
       " 99997 -0.539572 -0.505478         0  \n",
       " 99998 -0.539572  0.561618         0  \n",
       " 99999 -0.539572 -0.505478         0  \n",
       " \n",
       " [100000 rows x 11 columns],\n",
       " 0        1\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        1\n",
       "         ..\n",
       " 99995    1\n",
       " 99996    0\n",
       " 99997    0\n",
       " 99998    0\n",
       " 99999    0\n",
       " Name: Survived, Length: 100000, dtype: int64,\n",
       "           Name  Ticket  Sex    Pclass           Age      Fare     SibSp  \\\n",
       " 0      17441.0    49.0  1.0 -1.425730 -8.614253e-16  0.134351  1.901268   \n",
       " 1       3063.0    49.0  1.0  0.877699 -8.614253e-16 -0.533837 -0.539572   \n",
       " 2      17798.0    14.0  1.0  0.877699 -2.069149e+00  1.070483  0.680848   \n",
       " 3      12742.0     0.0  1.0  0.877699 -9.374220e-01 -0.555506 -0.539572   \n",
       " 4       2335.0    49.0  1.0  0.877699 -5.737175e-01 -1.023540 -0.539572   \n",
       " ...        ...     ...  ...       ...           ...       ...       ...   \n",
       " 99995   1590.0    21.0  0.0 -0.274016  1.669127e+00 -0.434567 -0.539572   \n",
       " 99996   2992.0    49.0  1.0 -0.274016  1.911597e+00 -0.698959 -0.539572   \n",
       " 99997   4219.0    49.0  1.0  0.877699  1.536915e-01 -0.802137 -0.539572   \n",
       " 99998   3941.0    49.0  1.0  0.877699  1.002335e+00  0.259408 -0.539572   \n",
       " 99999   7055.0    49.0  1.0  0.877699  1.244805e+00 -0.492531 -0.539572   \n",
       " \n",
       "           Parch  Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       " 0     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 1     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 2      1.628715      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 3     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 4     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " ...         ...      ...      ...  ...      ...      ...      ...      ...   \n",
       " 99995 -0.505478      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       " 99996 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99997 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99998  0.561618      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99999 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " \n",
       "        Cabin_T  Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       " 0          0.0      0.0         0.0         0.0         1.0         0.0  \n",
       " 1          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 2          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 3          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 4          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " ...        ...      ...         ...         ...         ...         ...  \n",
       " 99995      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " 99996      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99997      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99998      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99999      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " \n",
       " [100000 rows x 21 columns],\n",
       " 1,\n",
       " {'parameter': 'Hyperparameters',\n",
       "  'auc': 'AUC',\n",
       "  'confusion_matrix': 'Confusion Matrix',\n",
       "  'threshold': 'Threshold',\n",
       "  'pr': 'Precision Recall',\n",
       "  'error': 'Prediction Error',\n",
       "  'class_report': 'Class Report',\n",
       "  'rfe': 'Feature Selection',\n",
       "  'learning': 'Learning Curve',\n",
       "  'manifold': 'Manifold Learning',\n",
       "  'calibration': 'Calibration Curve',\n",
       "  'vc': 'Validation Curve',\n",
       "  'dimension': 'Dimensions',\n",
       "  'feature': 'Feature Importance',\n",
       "  'feature_all': 'Feature Importance (All)',\n",
       "  'boundary': 'Decision Boundary',\n",
       "  'lift': 'Lift Chart',\n",
       "  'gain': 'Gain Chart',\n",
       "  'tree': 'Decision Tree'},\n",
       " False,\n",
       " True,\n",
       " LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               device='gpu', importance_type='split', learning_rate=0.1,\n",
       "               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=20210604, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0),\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                device='gpu', importance_type='split', learning_rate=0.1,\n",
       "                max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "                min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "                objective=None, random_state=20210604, reg_alpha=0.0,\n",
       "                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                subsample_for_bin=200000, subsample_freq=0),\n",
       "           Name  Ticket  Sex    Pclass           Age      Fare     SibSp  \\\n",
       " 0      17441.0    49.0  1.0 -1.425730 -8.614253e-16  0.134351  1.901268   \n",
       " 1       3063.0    49.0  1.0  0.877699 -8.614253e-16 -0.533837 -0.539572   \n",
       " 2      17798.0    14.0  1.0  0.877699 -2.069149e+00  1.070483  0.680848   \n",
       " 3      12742.0     0.0  1.0  0.877699 -9.374220e-01 -0.555506 -0.539572   \n",
       " 4       2335.0    49.0  1.0  0.877699 -5.737175e-01 -1.023540 -0.539572   \n",
       " ...        ...     ...  ...       ...           ...       ...       ...   \n",
       " 99995   1590.0    21.0  0.0 -0.274016  1.669127e+00 -0.434567 -0.539572   \n",
       " 99996   2992.0    49.0  1.0 -0.274016  1.911597e+00 -0.698959 -0.539572   \n",
       " 99997   4219.0    49.0  1.0  0.877699  1.536915e-01 -0.802137 -0.539572   \n",
       " 99998   3941.0    49.0  1.0  0.877699  1.002335e+00  0.259408 -0.539572   \n",
       " 99999   7055.0    49.0  1.0  0.877699  1.244805e+00 -0.492531 -0.539572   \n",
       " \n",
       "           Parch  Cabin_A  Cabin_B  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       " 0     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 1     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 2      1.628715      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 3     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 4     -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " ...         ...      ...      ...  ...      ...      ...      ...      ...   \n",
       " 99995 -0.505478      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       " 99996 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99997 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99998  0.561618      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " 99999 -0.505478      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       " \n",
       "        Cabin_T  Cabin_X  Embarked_C  Embarked_Q  Embarked_S  Embarked_X  \n",
       " 0          0.0      0.0         0.0         0.0         1.0         0.0  \n",
       " 1          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 2          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 3          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 4          0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " ...        ...      ...         ...         ...         ...         ...  \n",
       " 99995      0.0      0.0         1.0         0.0         0.0         0.0  \n",
       " 99996      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99997      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99998      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " 99999      0.0      1.0         0.0         0.0         1.0         0.0  \n",
       " \n",
       " [100000 rows x 21 columns],\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x1afb53f02c8>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x1afb53dc048>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x1afb53dc308>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x1afb53dc408>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x1afb53dc848>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x1afb53dc9c8>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x1afb53dce48>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x1afb5305088>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x1afb53054c8>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x1afb53dc488>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x1afb53ebbc8>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x1afb5276648>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x1afb53dc888>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x1afb53ebc08>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x1afb5308088>,\n",
       "  'xgboost': <pycaret.containers.models.classification.XGBClassifierContainer at 0x1afb53e5e88>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x1afb5305a88>,\n",
       "  'catboost': <pycaret.containers.models.classification.CatBoostClassifierContainer at 0x1afb53086c8>,\n",
       "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x1afb53087c8>,\n",
       "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x1afb530a6c8>,\n",
       "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x1afb530a748>,\n",
       "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x1afb530ab08>},\n",
       " Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False),\n",
       " 'Survived',\n",
       " Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=['Cabin',\n",
       "                                                             'Embarked'],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=['Name', 'Ticket',\n",
       "                                                           'Sex', 'Pclass',\n",
       "                                                           'Age', 'Fare',\n",
       "                                                           'SibSp', 'Parch'],\n",
       "                                       target='Survived', time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Iterative_Imputer(add_indicator=False,\n",
       "                                    c...\n",
       "                 ('scaling', 'passthrough'), ('P_transform', 'passthrough'),\n",
       "                 ('binn', 'passthrough'), ('rem_outliers', 'passthrough'),\n",
       "                 ('cluster_all', 'passthrough'),\n",
       "                 ('dummy', Dummify(target='Survived')),\n",
       "                 ('fix_perfect', Remove_100(target='Survived')),\n",
       "                 ('clean_names', Clean_Colum_Names()),\n",
       "                 ('feature_select', 'passthrough'), ('fix_multi', 'passthrough'),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "          verbose=False),\n",
       " StratifiedKFold(n_splits=5, random_state=20210604, shuffle=True),\n",
       " '998c',\n",
       " 20210604,\n",
       " 100000    1\n",
       " 100001    1\n",
       " 100002    1\n",
       " 100003    1\n",
       " 100004    1\n",
       "          ..\n",
       " 199995    1\n",
       " 199996    1\n",
       " 199997    1\n",
       " 199998    1\n",
       " 199999    1\n",
       " Name: Survived, Length: 100000, dtype: int64,\n",
       " 0        1\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        1\n",
       "         ..\n",
       " 99995    1\n",
       " 99996    0\n",
       " 99997    0\n",
       " 99998    0\n",
       " 99999    0\n",
       " Name: Survived, Length: 100000, dtype: int32,\n",
       " False,\n",
       " 'clf-default-name')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct model\n",
    "# AutoML : mljar\n",
    "RESULTS_PATH = 'pycaret-20210604'\n",
    "SEED = 20210604\n",
    "\n",
    "setup(data = df_train[label_cols + onehot_cols + num_cols + [TARGET]],\n",
    "      categorical_features=onehot_cols,\n",
    "      numeric_features=label_cols + num_cols,\n",
    "      imputation_type='iterative',\n",
    "      target = TARGET,\n",
    "      train_size=1.0,\n",
    "      test_data = df_test,\n",
    "      data_split_shuffle=True,\n",
    "      data_split_stratify=True,\n",
    "      fold = 5,\n",
    "      fold_strategy='stratifiedkfold',   # or 'kfold', 'stratifiedkfold', 'groupkfold', 'timeseries'\n",
    "      fold_shuffle = True,\n",
    "      n_jobs=-1,\n",
    "      use_gpu = True,\n",
    "      session_id=SEED,   # seed\n",
    "      silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b27311b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: mljar-20210601\n",
      "Expected computing time:\n",
      "Total training time: Optuna + ML training = 61200 seconds\n",
      "Total Optuna time: len(algorithms) * optuna_time_budget = 32400 seconds\n",
      "Total ML model training time: 28800 seconds\n",
      "The task is binary_classification with evaluation metric accuracy\n",
      "AutoML will use algorithms: ['Baseline', 'Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble availabe models\n",
      "AutoML steps: ['simple_algorithms', 'default_algorithms', 'golden_features', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "1_Baseline accuracy 0.57226 trained in 21.2 seconds\n",
      "2_DecisionTree accuracy 0.75798 trained in 20.76 seconds\n",
      "* Step default_algorithms will try to check up to 7 models\n",
      "3_Optuna_LightGBM accuracy 0.78386 trained in 39.31 seconds\n",
      "4_Optuna_Xgboost accuracy 0.78219 trained in 43.67 seconds\n",
      "5_Optuna_CatBoost accuracy 0.78361 trained in 38.55 seconds\n",
      "6_Optuna_NeuralNetwork accuracy 0.78041 trained in 461.75 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Sex_ratio_Pclass\n",
      "Add Golden Feature: Pclass_ratio_Sex\n",
      "Add Golden Feature: Sex_multiply_Pclass\n",
      "Add Golden Feature: Sex_diff_Embarked_C\n",
      "Add Golden Feature: Embarked_S_sum_Sex\n",
      "Add Golden Feature: Fare_ratio_Sex\n",
      "Add Golden Feature: Sex_multiply_Fare\n",
      "Add Golden Feature: Sex_diff_Cabin_C\n",
      "Add Golden Feature: Cabin_X_sum_Sex\n",
      "Add Golden Feature: Embarked_S_ratio_Sex\n",
      "Created 10 Golden Features in 11.51 seconds.\n",
      "3_Optuna_LightGBM_GoldenFeatures accuracy 0.78386 trained in 53.29 seconds\n",
      "5_Optuna_CatBoost_GoldenFeatures accuracy 0.78338 trained in 42.39 seconds\n",
      "4_Optuna_Xgboost_GoldenFeatures accuracy 0.78152 trained in 50.5 seconds\n",
      "* Step boost_on_errors will try to check up to 1 model\n",
      "3_Optuna_LightGBM_BoostOnErrors accuracy 0.78308 trained in 44.18 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble accuracy 0.78386 trained in 18.62 seconds\n",
      "* Step stack will try to check up to 7 models\n",
      "3_Optuna_LightGBM_Stacked accuracy 0.78357 trained in 29.96 seconds\n",
      "5_Optuna_CatBoost_Stacked accuracy 0.7835 trained in 26.49 seconds\n",
      "4_Optuna_Xgboost_Stacked accuracy 0.78393 trained in 57.11 seconds\n",
      "6_Optuna_NeuralNetwork_Stacked accuracy 0.78224 trained in 629.09 seconds\n",
      "3_Optuna_LightGBM_GoldenFeatures_Stacked accuracy 0.7834 trained in 34.39 seconds\n",
      "5_Optuna_CatBoost_GoldenFeatures_Stacked accuracy 0.78376 trained in 35.29 seconds\n",
      "4_Optuna_Xgboost_GoldenFeatures_Stacked accuracy 0.78385 trained in 43.71 seconds\n",
      "* Step ensemble_stacked will try to check up to 1 model\n",
      "Ensemble_Stacked accuracy 0.78432 trained in 20.98 seconds\n",
      "AutoML fit time: 16730.19 seconds\n",
      "AutoML best model: Ensemble_Stacked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoML(algorithms=['Baseline', 'Linear', 'Decision Tree', 'Random Forest',\n",
       "                   'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost',\n",
       "                   'Neural Network', 'Nearest Neighbors'],\n",
       "       boost_on_errors=True, eval_metric='accuracy', golden_features=True,\n",
       "       ml_task='binary_classification', mode='Optuna', optuna_time_budget=3600,\n",
       "       optuna_verbose=False, random_state=20210601,\n",
       "       results_path='mljar-20210601', stack_models=True, total_time_limit=28800,\n",
       "       validation_strategy={'k_folds': 5, 'random_seed': 20210601,\n",
       "                            'shuffle': True, 'stratify': True,\n",
       "                            'validation_type': 'kfold'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model\n",
    "automl.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b872cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load well-trained model\n",
    "automl = AutoML(results_path=RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8f0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "x_test = df_test\n",
    "result = automl.predict(x_test)\n",
    "result = result.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bcb3b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub[sub.columns[1:]] = result\n",
    "sub.to_csv(f'{RESULTS_PATH}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eff0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
